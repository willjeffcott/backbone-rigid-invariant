{"cells":[{"cell_type":"markdown","metadata":{"id":"RYVvHHy6WGo5"},"source":["# 08 OpenFold Geometric Nearest Neighbours\n","# This notebook identifies overlapping chains between the User dataset and OpenFold,\n","# and performs a hierarchical geometric nearest neighbour search (Mean -> Full).\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLXwqXjUWGo7","executionInfo":{"status":"ok","timestamp":1770306334453,"user_tz":0,"elapsed":13538,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"2d0e7426-3b33-4d0e-90c6-309e9b6400a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Changed directory to /content/drive/MyDrive/BRI Analysis\n"]}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","# Change directory to the working folder if necessary\n","try:\n","    os.chdir('/content/drive/MyDrive/BRI Analysis')\n","    print(\"Changed directory to /content/drive/MyDrive/BRI Analysis\")\n","except:\n","    print(\"Could not change directory. Please check the path.\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhFHuBdnWGo8","executionInfo":{"status":"ok","timestamp":1770306336283,"user_tz":0,"elapsed":1828,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"d49a6d71-2699-4152-f7d6-c5f9cb37f739"},"outputs":[{"output_type":"stream","name":"stdout","text":["Environment Setup Complete.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import json\n","from scipy.spatial import cKDTree\n","import glob\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm.notebook import tqdm\n","import gc\n","\n","# Paths\n","DATA_DIR = './data'\n","PLOTS_DIR = './plotting/nearest_neighbours_08'\n","BRI_DATA_DIR = './data/bri_computations' # Adjust if necessary\n","\n","os.makedirs(PLOTS_DIR, exist_ok=True)\n","os.makedirs(DATA_DIR, exist_ok=True)\n","print(\"Environment Setup Complete.\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uEHEefWNWGo9","executionInfo":{"status":"ok","timestamp":1770306338414,"user_tz":0,"elapsed":2105,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"96c9bb45-49cd-4be6-b794-b65fbdb17a15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading User Data Mapping from ./data/cleaned_connective_chains_auth_chain_id.csv...\n","Loaded 478074 user chains.\n"]}],"source":["# @title 1. Load Data Mapping\n","# Load User Data Mapping (Label -> Author Chain ID) to bridge datasets.\n","\n","user_chain_map_path = os.path.join(DATA_DIR, 'cleaned_connective_chains_auth_chain_id.csv')\n","print(f\"Loading User Data Mapping from {user_chain_map_path}...\")\n","\n","if os.path.exists(user_chain_map_path):\n","    df_user = pd.read_csv(user_chain_map_path)\n","    # Ensure columns are strings\n","    df_user['pdb_id'] = df_user['pdb_id'].astype(str).str.upper()\n","    df_user['author_chain_id'] = df_user['author_chain_id'].astype(str)\n","    df_user['author_chain_id'] = df_user['author_chain_id'].fillna('NA')\n","    print(f\"Loaded {len(df_user)} user chains.\")\n","else:\n","    raise FileNotFoundError(f\"Mapping file not found: {user_chain_map_path}\")\n"]},{"cell_type":"code","source":["# @title 2. Generate mean invariants with corresponding batch number\n","\n","import os\n","import pandas as pd\n","import tqdm\n","import gc\n","\n","# @title 1. Generate Mean Invariants with Batch Numbers\n","inv_dir = \"./data/bri_computations\"\n","output_file = \"./data/PDB727K_mean_invariants_with_batch.csv\"\n","\n","if os.path.exists(output_file):\n","    os.remove(output_file)\n","\n","# Get files and sort them to ensure deterministic order (optional but good practice)\n","files = sorted([f for f in os.listdir(inv_dir) if f.endswith('.parquet')])\n","\n","def calculate_means(df):\n","    # Calculate means for unique group in 'pdb_id', 'model_id', 'chain_id'\n","    bri_cols = ['x(N)', 'y(N)', 'z(N)', 'x(A)', 'y(A)', 'z(A)', 'x(C)', 'y(C)',\n","       'z(C)']\n","\n","    means = df.groupby(['pdb_id', 'model_id', 'chain_id', 'start_residue', 'chain_length'])[bri_cols].mean().reset_index()\n","    return means\n","\n","\n","for i, filename in enumerate(tqdm.tqdm(files, desc=\"Processing Batches\")):\n","    try:\n","        # Extract batch number from filename \"batch_123.parquet\"\n","        # Adjust split logic if your naming convention differs\n","        try:\n","            batch_num = int(filename.split('_')[1].split('.')[0])\n","        except (IndexError, ValueError):\n","            # Fallback if filename is weird, though user stated \"batch_i.parquet\"\n","            print(f\"Warning: Could not parse batch number from {filename}. assigning {i}.\")\n","            batch_num = i\n","\n","        inv_data = pd.read_parquet(os.path.join(inv_dir, filename))\n","\n","        inv_data['chain_id'] = inv_data['chain_id'].astype(str)\n","        inv_data['chain_id'] = inv_data['chain_id'].fillna('NA')\n","\n","        # Calculate means\n","        mean_data = calculate_means(inv_data)\n","\n","        # --- ADD BATCH NUMBER ---\n","        mean_data['batch_number'] = batch_num\n","\n","        # Write incrementally\n","        mode = 'w' if i == 0 else 'a'\n","        header = (i == 0)\n","        mean_data.to_csv(output_file, index=False, mode=mode, header=header)\n","\n","        del inv_data, mean_data\n","        if i % 10 == 0: gc.collect()\n","\n","    except Exception as e:\n","        print(f\"Skipping {filename} due to error: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jtZ379Vb8Zk","executionInfo":{"status":"ok","timestamp":1770307046786,"user_tz":0,"elapsed":90038,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"745ab175-a9aa-406d-c578-35736ed627e7"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Batches: 100%|██████████| 146/146 [01:30<00:00,  1.62it/s]\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RVU3mfwPWGo-","executionInfo":{"status":"ok","timestamp":1770307050684,"user_tz":0,"elapsed":3847,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"70d0c1b7-7ff0-4d40-d865-04c83b4843ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading OpenFold duplicate chains...\n","Found 472464 OpenFold duplicate chains.\n","Loading OpenFold Chain Cache...\n","Loaded 128793 unique OpenFold chains.\n"]}],"source":["# @title 3. Load OpenFold Data\n","# Load Duplicate list and Chain Cache to identify valid OpenFold chains.\n","\n","of_cache_path = os.path.join(DATA_DIR, 'openfold_chain_data_cache.json')\n","of_duplicates_path = os.path.join(DATA_DIR, 'openfold_duplicate_chains.txt')\n","\n","of_duplicates = set()\n","if os.path.exists(of_duplicates_path):\n","    print(\"Loading OpenFold duplicate chains...\")\n","    with open(of_duplicates_path, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            if len(parts) > 1:\n","                # Exclude representative (first item) and keep duplicates\n","                for dup in parts[1:]:\n","                    of_duplicates.add(dup.upper())\n","    print(f\"Found {len(of_duplicates)} OpenFold duplicate chains.\")\n","else:\n","    print(\"Warning: OpenFold duplicate chains file not found. Skipping duplicate filter.\")\n","\n","print(\"Loading OpenFold Chain Cache...\")\n","if os.path.exists(of_cache_path):\n","    with open(of_cache_path, 'r') as f:\n","        of_data = json.load(f)\n","\n","    of_chains = set()\n","    for key in of_data:\n","        if key.upper() not in of_duplicates:\n","            # key format is '1ABC_A'\n","            parts = key.split('_')\n","            if len(parts) >= 2:\n","                pdb_id = parts[0].upper()\n","                chain_id = parts[1]\n","                # if chain_id is np.nan then convert to 'NA'\n","                if pd.isna(chain_id):\n","                    chain_id = 'NA'\n","\n","                of_chains.add((pdb_id, chain_id))\n","    print(f\"Loaded {len(of_chains)} unique OpenFold chains.\")\n","else:\n","    raise FileNotFoundError(f\"OpenFold cache not found: {of_cache_path}\")\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0lGH-PyWGo-","executionInfo":{"status":"ok","timestamp":1770307051106,"user_tz":0,"elapsed":33,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"4828c34f-8d7a-47a8-bb01-40bbdd629c3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 58971 overlapping chains.\n"]}],"source":["# @title 3. Identify Overlap\n","# Find intersection: User (Author Chain ID) ∩ OpenFold (Chain ID)\n","\n","user_keys = set(zip(df_user['pdb_id'], df_user['author_chain_id']))\n","overlap_keys = user_keys.intersection(of_chains)\n","target_chains_set = set(overlap_keys)\n","\n","print(f\"Found {len(overlap_keys)} overlapping chains.\")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jq2I3CWYWGo_","executionInfo":{"status":"ok","timestamp":1770307058028,"user_tz":0,"elapsed":6920,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"be7833bf-19eb-4696-8ea7-d176bb3cf6ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Mean Invariants from ./data/PDB727K_mean_invariants_with_batch.csv...\n","Merging with Author Chain IDs...\n","Original Mean Invariants: 477859\n","Filtered Target Mean Invariants: 58929\n"]}],"source":["# @title 4. Filter Mean Invariants\n","# Filter the user's mean invariants file to only include the overlapping chains.\n","\n","mean_invariants_path = os.path.join(DATA_DIR, 'PDB727K_mean_invariants_with_batch.csv')\n","print(f\"Loading Mean Invariants from {mean_invariants_path}...\")\n","\n","if os.path.exists(mean_invariants_path):\n","    df_mean = pd.read_csv(mean_invariants_path)\n","    # Check column names for PDB/Chain\n","    # Assuming 'pdb_id' and 'chain_id' (Label) are present\n","    df_mean['pdb_id'] = df_mean['pdb_id'].astype(str).str.upper()\n","    df_mean['chain_id'] = df_mean['chain_id'].astype(str)\n","    df_mean['chain_id'] = df_mean['chain_id'].fillna('NA')\n","\n","    df_mean = df_mean[df_mean['model_id']==1].copy()\n","\n","    # Map to Author ID using user_map\n","    df_user_map = df_user[['pdb_id', 'chain_id', 'author_chain_id']].drop_duplicates()\n","\n","    print(\"Merging with Author Chain IDs...\")\n","    df_mean_mapped = df_mean.merge(df_user_map, on=['pdb_id', 'chain_id'], how='inner')\n","\n","    # Filter by target_chains_set (pdb_id, author_chain_id)\n","    df_mean_mapped['match_key'] = list(zip(df_mean_mapped['pdb_id'], df_mean_mapped['author_chain_id']))\n","    df_target = df_mean_mapped[df_mean_mapped['match_key'].isin(target_chains_set)].copy()\n","\n","    print(f\"Original Mean Invariants: {len(df_mean)}\")\n","    print(f\"Filtered Target Mean Invariants: {len(df_target)}\")\n","\n","    # Clean up to save memory\n","    #del df_mean, df_mean_mapped\n","    #gc.collect()\n","else:\n","    raise FileNotFoundError(f\"Mean Invariants file not found: {mean_invariants_path}\")\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYMAxfHiWGpA","executionInfo":{"status":"ok","timestamp":1770307508863,"user_tz":0,"elapsed":1753,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"98767608-c1d2-49a5-898b-238d30bd579e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using 9 features for comparison.\n","Writing pairs to ./data/PDB727K_openfold_mean_pairs.csv...\n"]},{"output_type":"stream","name":"stderr","text":["Processing Lengths: 100%|██████████| 984/984 [00:01<00:00, 570.64it/s]"]},{"output_type":"stream","name":"stdout","text":["Phase 1 Complete. Found 12379 pairs.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# @title 5. Phase 1: Mean Invariant Comparison\n","# Perform coarse nearest neighbour search using Mean Invariants with Chebyshev distance.\n","\n","mean_pairs_output = os.path.join(DATA_DIR, 'PDB727K_openfold_mean_pairs.csv')\n","RADIUS = 0.01\n","\n","# Identify Feature Columns (assuming numeric columns excluding metadata)\n","meta_cols = {'pdb_id', 'chain_id', 'author_chain_id', 'model_id', 'start_residue', 'chain_length', 'batch_number', 'match_key'}\n","feature_cols = [c for c in df_target.columns if c not in meta_cols and np.issubdtype(df_target[c].dtype, np.number)]\n","\n","# Sanity check for feature columns\n","if len(feature_cols) < 5:\n","    print(f\"Warning: Only found {len(feature_cols)} features. Checking for 'inv_' prefix.\")\n","    feature_cols = [c for c in df_target.columns if c.startswith('inv_')]\n","\n","print(f\"Using {len(feature_cols)} features for comparison.\")\n","\n","# Prepare Output\n","id_cols = ['pdb_id', 'chain_id', 'author_chain_id', 'chain_length', 'batch_number']\n","header = [f\"{c}_1\" for c in id_cols] + [f\"{c}_2\" for c in id_cols] + ['chebyshev_dist']\n","\n","# Group by Chain Length\n","grouped = df_target.groupby('chain_length')\n","total_pairs = 0\n","\n","print(f\"Writing pairs to {mean_pairs_output}...\")\n","with open(mean_pairs_output, 'w') as f_out:\n","    f_out.write(','.join(header) + '\\n')\n","\n","    for length, group in tqdm.tqdm(grouped, desc=\"Processing Lengths\"):\n","        if len(group) < 2: continue\n","\n","        points = group[feature_cols].values\n","\n","        # Build cKDTree\n","        try:\n","            tree = cKDTree(points)\n","            # Query pairs within Radius (p=np.inf for Chebyshev)\n","            pairs = tree.query_pairs(r=RADIUS, p=np.inf)\n","        except Exception as e:\n","            print(f\"Error processing length {length}: {e}\")\n","            continue\n","\n","        if not pairs: continue\n","\n","        pairs_arr = np.array(list(pairs))\n","\n","        # Calculate precise distances for retrieved pairs\n","        p1 = points[pairs_arr[:, 0]]\n","        p2 = points[pairs_arr[:, 1]]\n","        dists = np.max(np.abs(p1 - p2), axis=1)\n","\n","        # Retrieve IDs\n","        res1 = group.iloc[pairs_arr[:, 0]][id_cols].reset_index(drop=True)\n","        res2 = group.iloc[pairs_arr[:, 1]][id_cols].reset_index(drop=True)\n","\n","        res1.columns = [f\"{c}_1\" for c in id_cols]\n","        res2.columns = [f\"{c}_2\" for c in id_cols]\n","\n","        res_df = pd.concat([res1, res2], axis=1)\n","        res_df['chebyshev_dist'] = dists\n","\n","        # Append to CSV\n","        res_df.to_csv(f_out, header=False, index=False)\n","        total_pairs += len(res_df)\n","\n","print(f\"Phase 1 Complete. Found {total_pairs} pairs.\")\n"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUG8XMFgWGpB","executionInfo":{"status":"ok","timestamp":1770308740691,"user_tz":0,"elapsed":71305,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"34cd111e-c0c1-458d-adc9-9a77ae5d15c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading pairs to identify relevant chains...\n","Building set of required chains (Assuming Model ID = 1)...\n","Total unique chains to load: 3765\n","Scanning 146 batch files...\n"]},{"output_type":"stream","name":"stderr","text":["Loading Data: 100%|██████████| 146/146 [01:10<00:00,  2.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Successfully loaded 3765 chains into memory.\n","Computing pairwise comparisons...\n"]},{"output_type":"stream","name":"stderr","text":["Comparing: 100%|██████████| 12379/12379 [00:01<00:00, 11311.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved 149 passing pairs to ./data/PDB727K_full_comparison_results_001_seq_openfold.csv\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import tqdm\n","import gc\n","\n","# @title 6. Full Comparison (Memory Optimized: Filter-on-Load)\n","# ==============================================================================\n","# Configuration\n","# ==============================================================================\n","pairs_file = f\"./data/PDB727K_openfold_mean_pairs.csv\"\n","parquet_dir = \"./data/bri_computations\"\n","output_full_diff_file = f\"./data/PDB727K_full_comparison_results_001_seq_openfold.csv\"\n","\n","full_dist_threshold = 0.01\n","\n","# Columns to load from Parquet\n","# We still load 'model_id' to filter by it, even if we assume it is 1\n","id_cols = ['pdb_id', 'model_id', 'chain_id']\n","bri_cols = ['x(N)', 'y(N)', 'z(N)', 'x(A)', 'y(A)', 'z(A)', 'x(C)', 'y(C)', 'z(C)']\n","seq_col = 'residue_label'\n","\n","load_columns = list(set(id_cols + bri_cols + [seq_col]))\n","\n","# ==============================================================================\n","# 1. Identify \"Relevant Chains\"\n","# ==============================================================================\n","if not os.path.exists(pairs_file):\n","    raise FileNotFoundError(\"Run Step 2 first.\")\n","\n","print(\"Loading pairs to identify relevant chains...\")\n","pairs_df = pd.read_csv(pairs_file)\n","\n","if len(pairs_df) == 0:\n","    print(\"No pairs found.\")\n","    exit()\n","\n","# Extract unique keys (Chain 1 and Chain 2) needed for analysis\n","# We use a set of tuples for O(1) lookup: (pdb_id, model_id, chain_id, start_residue, chain_length)\n","# CHANGE: We assume model_id is always 1, so we inject '1' into the key tuples manually.\n","\n","print(\"Building set of required chains (Assuming Model ID = 1)...\")\n","\n","# Create vectors of 1s for the zip operation\n","ones_vector = [1] * len(pairs_df)\n","\n","keys_1 = list(zip(\n","    pairs_df['pdb_id_1'],\n","    ones_vector,          # Hardcoded Model ID 1\n","    pairs_df['chain_id_1']\n","))\n","\n","keys_2 = list(zip(\n","    pairs_df['pdb_id_2'],\n","    ones_vector,          # Hardcoded Model ID 1\n","    pairs_df['chain_id_2']\n","))\n","\n","required_keys = set(keys_1) | set(keys_2)\n","\n","print(f\"Total unique chains to load: {len(required_keys)}\")\n","\n","# ==============================================================================\n","# 2. Load and Filter Data (One Pass over Files)\n","# ==============================================================================\n","# Store data as: chain_data_store[key] = {'mat': np.array, 'seq': str}\n","chain_data_store = {}\n","\n","# Get list of batch files\n","batch_files = sorted([f for f in os.listdir(parquet_dir) if f.endswith('.parquet')])\n","\n","print(f\"Scanning {len(batch_files)} batch files...\")\n","\n","for f in tqdm.tqdm(batch_files, desc=\"Loading Data\"):\n","    try:\n","        path = os.path.join(parquet_dir, f)\n","\n","        # Load batch (only relevant columns)\n","        df = pd.read_parquet(path, columns=load_columns)\n","\n","        # --- NEW FILTERING STEP ---\n","        # Strictly filter for model_id == 1\n","        df = df[df['model_id'] == 1]\n","\n","        if df.empty:\n","            continue\n","\n","        # Create a tuple key column for filtering\n","        # Note: Vectorized zip is faster than apply\n","        current_keys = list(zip(\n","            df['pdb_id'],\n","            df['model_id'],\n","            df['chain_id']\n","        ))\n","\n","        # Filter: keep rows where the key is in our required set\n","        mask = [k in required_keys for k in current_keys]\n","\n","        if not any(mask):\n","            continue # Nothing useful in this batch\n","\n","        filtered_df = df[mask].copy()\n","\n","        # Group by chain to extract Matrix and Sequence\n","        # We groupby the full key\n","        grouped = filtered_df.groupby(id_cols)\n","\n","        for key, group in grouped:\n","            # key is the tuple (pdb, model, chain, start, length)\n","\n","            # Extract Matrix\n","            mat = group[bri_cols].to_numpy()\n","\n","            # Extract Sequence\n","            labels = group[seq_col]\n","            if len(labels) > 0 and isinstance(labels.iloc[0], str):\n","                # Standard case: sequence of characters\n","                seq = \"\".join(labels)\n","            else:\n","                seq = \"\"\n","\n","            chain_data_store[key] = {'mat': mat, 'seq': seq}\n","\n","        del df, filtered_df, mask, current_keys\n","        # gc.collect()\n","\n","    except Exception as e:\n","        print(f\"Error reading {f}: {e}\")\n","\n","print(f\"Successfully loaded {len(chain_data_store)} chains into memory.\")\n","\n","# ==============================================================================\n","# 3. Compute Distances\n","# ==============================================================================\n","print(\"Computing pairwise comparisons...\")\n","\n","results_list = []\n","\n","# Iterate through pairs and lookup data from memory\n","for idx, row in tqdm.tqdm(pairs_df.iterrows(), total=len(pairs_df), desc=\"Comparing\"):\n","\n","    # CHANGE: Hardcoded '1' for model_id in the lookup key\n","    key1 = (row['pdb_id_1'], 1, row['chain_id_1'])\n","    key2 = (row['pdb_id_2'], 1, row['chain_id_2'])\n","\n","    # Retrieve data\n","    if key1 not in chain_data_store or key2 not in chain_data_store:\n","        # Should not happen if logic is correct, but safe to skip\n","        continue\n","\n","    data1 = chain_data_store[key1]\n","    data2 = chain_data_store[key2]\n","\n","    mat1 = data1['mat']\n","    mat2 = data2['mat']\n","\n","    # Check length compatibility\n","    min_len = min(len(mat1), len(mat2))\n","\n","    # Compute Distance\n","    dist = np.max(np.abs(mat1[:min_len] - mat2[:min_len]))\n","\n","    # Check Threshold\n","    if dist <= full_dist_threshold:\n","        seq1 = data1['seq']\n","        seq2 = data2['seq']\n","\n","        res_row = row.to_dict()\n","        res_row['full_chebyshev_dist'] = dist\n","        res_row['sequence_1'] = seq1\n","        res_row['sequence_2'] = seq2\n","        res_row['sequences_identical'] = 1 if seq1 == seq2 else 0\n","\n","        results_list.append(res_row)\n","\n","# ==============================================================================\n","# 4. Save Results\n","# ==============================================================================\n","if results_list:\n","    final_df = pd.DataFrame(results_list)\n","    final_df.to_csv(output_full_diff_file, index=False)\n","    print(f\"Saved {len(final_df)} passing pairs to {output_full_diff_file}\")\n","else:\n","    print(\"No pairs passed the full distance threshold.\")"]},{"cell_type":"code","source":["final_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"Ox3ceKEOo913","executionInfo":{"status":"ok","timestamp":1770309058301,"user_tz":0,"elapsed":55,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"b4dc0b5b-6dbf-4e2e-f07a-ed9ce158fc0a"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    pdb_id_1 chain_id_1 author_chain_id_1  chain_length_1  batch_number_1  \\\n","0       3S8L          B                 B               1              60   \n","1       4UCA          C                 C               1              68   \n","2       6EIT          D                 4               1              87   \n","3       3S8L          B                 B               1              60   \n","4       4TTK          A                 A               1              67   \n","..       ...        ...               ...             ...             ...   \n","144     1C2B          A                 A             539               1   \n","145     1Q55          A                 A             540              13   \n","146     7ADJ          A                 A             613             105   \n","147     5N8P          A                 A             778              79   \n","148     1F4A          A                 A            1021               4   \n","\n","    pdb_id_2 chain_id_2 author_chain_id_2  chain_length_2  batch_number_2  \\\n","0       4GR7          A                 X               1              64   \n","1       5ETF          B                 B               1              74   \n","2       6G8K          B                 P               1              88   \n","3       4Z33          C                 C               1              72   \n","4       6CNU          A                 A               1              86   \n","..       ...        ...               ...             ...             ...   \n","144     1C2O          A                 A             539               1   \n","145     1L3W          A                 A             540               9   \n","146     7ADK          A                 A             613             105   \n","147     5N97          A                 A             778              79   \n","148     4CKD          A                 A            1021              63   \n","\n","     chebyshev_dist  full_chebyshev_dist  \\\n","0          0.007000                0.007   \n","1          0.006000                0.006   \n","2          0.009000                0.009   \n","3          0.009000                0.009   \n","4          0.005000                0.005   \n","..              ...                  ...   \n","144        0.000134                0.005   \n","145        0.000039                0.002   \n","146        0.000000                0.000   \n","147        0.000035                0.002   \n","148        0.000035                0.002   \n","\n","                                            sequence_1  \\\n","0                                                    N   \n","1                                                    F   \n","2                                                    P   \n","3                                                    N   \n","4                                                    G   \n","..                                                 ...   \n","144  DPQLLVRVRGGQLRGIRLKAPGGPVSAFLGIPFAEPPVGSRRFMPP...   \n","145  DWVIPPIKVSENERGPFPKRLVQIKSNKDRFNKVYYSITGQGADNP...   \n","146  RKQTITIAGIEVEAEIEGPPGFVTHQRDKDRKISNPTKPYQNHTVN...   \n","147  GSTLSLTTGTDTLTGTANNDTFVAGEVAGAATLTVGDTLSGGAGTD...   \n","148  ITDSLAVVLQRRDWENPGVTQLNRLAAHPPFASWRNSEEARTDRPS...   \n","\n","                                            sequence_2  sequences_identical  \n","0                                                    M                    0  \n","1                                                    L                    0  \n","2                                                    A                    0  \n","3                                                    K                    0  \n","4                                                    G                    1  \n","..                                                 ...                  ...  \n","144  DPQLLVRVRGGQLRGIRLKAPGGPVSAFLGIPFAEPPVGSRRFMPP...                    1  \n","145  DWVIPPIKVSENERGPFPKRLVQIKSNKDRFNKVYYSITGQGADNP...                    1  \n","146  RKQTITIAGIEVEAEIEGPPGFVTHQRDKDRKISNPTKPYQNHTVN...                    1  \n","147  GSTLSLTTGTDTLTGTANNDTFVAGEVAGAATLTVGDTLSGGAGTD...                    1  \n","148  ITDSLAVVLQRRDWENPGVTQLNRLAAHPPFASWRNSEEARTDRPS...                    1  \n","\n","[149 rows x 15 columns]"],"text/html":["\n","  <div id=\"df-e2d15cf6-8ea8-43c2-a074-817dedfd737a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pdb_id_1</th>\n","      <th>chain_id_1</th>\n","      <th>author_chain_id_1</th>\n","      <th>chain_length_1</th>\n","      <th>batch_number_1</th>\n","      <th>pdb_id_2</th>\n","      <th>chain_id_2</th>\n","      <th>author_chain_id_2</th>\n","      <th>chain_length_2</th>\n","      <th>batch_number_2</th>\n","      <th>chebyshev_dist</th>\n","      <th>full_chebyshev_dist</th>\n","      <th>sequence_1</th>\n","      <th>sequence_2</th>\n","      <th>sequences_identical</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3S8L</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>60</td>\n","      <td>4GR7</td>\n","      <td>A</td>\n","      <td>X</td>\n","      <td>1</td>\n","      <td>64</td>\n","      <td>0.007000</td>\n","      <td>0.007</td>\n","      <td>N</td>\n","      <td>M</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4UCA</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>1</td>\n","      <td>68</td>\n","      <td>5ETF</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>74</td>\n","      <td>0.006000</td>\n","      <td>0.006</td>\n","      <td>F</td>\n","      <td>L</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6EIT</td>\n","      <td>D</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>87</td>\n","      <td>6G8K</td>\n","      <td>B</td>\n","      <td>P</td>\n","      <td>1</td>\n","      <td>88</td>\n","      <td>0.009000</td>\n","      <td>0.009</td>\n","      <td>P</td>\n","      <td>A</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3S8L</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>60</td>\n","      <td>4Z33</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>1</td>\n","      <td>72</td>\n","      <td>0.009000</td>\n","      <td>0.009</td>\n","      <td>N</td>\n","      <td>K</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4TTK</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>67</td>\n","      <td>6CNU</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>86</td>\n","      <td>0.005000</td>\n","      <td>0.005</td>\n","      <td>G</td>\n","      <td>G</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>1C2B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>539</td>\n","      <td>1</td>\n","      <td>1C2O</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>539</td>\n","      <td>1</td>\n","      <td>0.000134</td>\n","      <td>0.005</td>\n","      <td>DPQLLVRVRGGQLRGIRLKAPGGPVSAFLGIPFAEPPVGSRRFMPP...</td>\n","      <td>DPQLLVRVRGGQLRGIRLKAPGGPVSAFLGIPFAEPPVGSRRFMPP...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>1Q55</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>540</td>\n","      <td>13</td>\n","      <td>1L3W</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>540</td>\n","      <td>9</td>\n","      <td>0.000039</td>\n","      <td>0.002</td>\n","      <td>DWVIPPIKVSENERGPFPKRLVQIKSNKDRFNKVYYSITGQGADNP...</td>\n","      <td>DWVIPPIKVSENERGPFPKRLVQIKSNKDRFNKVYYSITGQGADNP...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>7ADJ</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>613</td>\n","      <td>105</td>\n","      <td>7ADK</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>613</td>\n","      <td>105</td>\n","      <td>0.000000</td>\n","      <td>0.000</td>\n","      <td>RKQTITIAGIEVEAEIEGPPGFVTHQRDKDRKISNPTKPYQNHTVN...</td>\n","      <td>RKQTITIAGIEVEAEIEGPPGFVTHQRDKDRKISNPTKPYQNHTVN...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>5N8P</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>778</td>\n","      <td>79</td>\n","      <td>5N97</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>778</td>\n","      <td>79</td>\n","      <td>0.000035</td>\n","      <td>0.002</td>\n","      <td>GSTLSLTTGTDTLTGTANNDTFVAGEVAGAATLTVGDTLSGGAGTD...</td>\n","      <td>GSTLSLTTGTDTLTGTANNDTFVAGEVAGAATLTVGDTLSGGAGTD...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>1F4A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>1021</td>\n","      <td>4</td>\n","      <td>4CKD</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>1021</td>\n","      <td>63</td>\n","      <td>0.000035</td>\n","      <td>0.002</td>\n","      <td>ITDSLAVVLQRRDWENPGVTQLNRLAAHPPFASWRNSEEARTDRPS...</td>\n","      <td>ITDSLAVVLQRRDWENPGVTQLNRLAAHPPFASWRNSEEARTDRPS...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>149 rows × 15 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2d15cf6-8ea8-43c2-a074-817dedfd737a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e2d15cf6-8ea8-43c2-a074-817dedfd737a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e2d15cf6-8ea8-43c2-a074-817dedfd737a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_653809d9-877c-48f6-ae5f-7a8d5b975b4d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_653809d9-877c-48f6-ae5f-7a8d5b975b4d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('final_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"final_df","summary":"{\n  \"name\": \"final_df\",\n  \"rows\": 149,\n  \"fields\": [\n    {\n      \"column\": \"pdb_id_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 92,\n        \"samples\": [\n          \"3MHV\",\n          \"1A7Z\",\n          \"2XQL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_id_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"B\",\n          \"G\",\n          \"OA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_chain_id_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"P\",\n          \"H\",\n          \"Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_length_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 151,\n        \"min\": 1,\n        \"max\": 1021,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          1,\n          41,\n          147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_number_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33,\n        \"min\": 0,\n        \"max\": 114,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          58,\n          56,\n          92\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdb_id_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 87,\n        \"samples\": [\n          \"3J2J\",\n          \"4GR7\",\n          \"3U8O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_id_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"K\",\n          \"X\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_chain_id_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 36,\n        \"samples\": [\n          \"1\",\n          \"D\",\n          \"O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_length_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 151,\n        \"min\": 1,\n        \"max\": 1021,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          1,\n          41,\n          147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_number_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 1,\n        \"max\": 114,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          18,\n          93,\n          109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chebyshev_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003658558098646571,\n        \"min\": 0.0,\n        \"max\": 0.0099999999999998,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          0.0001571428571429,\n          0.0069999999999998,\n          0.0002799999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_chebyshev_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002759578408219619,\n        \"min\": 0.0,\n        \"max\": 0.009999999999999898,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0.0010000000000000009,\n          0.0030000000000000027,\n          0.006999999999999895\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 82,\n        \"samples\": [\n          \"GEQYYKDAMEQCHNYNARLCAERSVRLPFLDSQTGVAQSNCYIWMEKRHRGPGLASGQLYSYPARRWRKK\",\n          \"N\",\n          \"DRASKIEQIQKLAKYAISALNYEDLPTAKDELTKALDLLNSI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 82,\n        \"samples\": [\n          \"EEEEEEEELVDPLTTVREQCEQLEKCVKARERLELCDERVSSRSHTEEDCTEELFDFLHARDHCVAHKLFNNLK\",\n          \"M\",\n          \"ATLKYICAECSSKLSLSRTDAVRCKDCGHRILLKARTKRLVQFEAR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequences_identical\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":37}]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S38rIMFoWGpC","executionInfo":{"status":"ok","timestamp":1770308957045,"user_tz":0,"elapsed":1192,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"1792fb63-f829-40b0-81fd-1642bd08adad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data for plotting...\n","Saved: ./plotting/nearest_neighbours_001A_openfold/PDB727K_pairwise_BRI_comparisons_different_seq.png\n","Saved: ./plotting/nearest_neighbours_001A_openfold/PDB727K_pairwise_BRI_comparisons_identical_seq.png\n","Saved: ./plotting/nearest_neighbours_001A_openfold/PDB727K_pairwise_BRI_comparisons_different_seq_log.png\n","Saved: ./plotting/nearest_neighbours_001A_openfold/PDB727K_pairwise_BRI_comparisons_identical_seq_log.png\n"]}],"source":["# @title 7. Visualization\n","# Generate histogram of pairwise L-inf distances.\n","\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Configuration\n","restrict_suffix = \"\"\n","input_file = f\"./data/PDB727K_full_comparison_results_001_seq_openfold.csv\"\n","output_dir = './plotting/nearest_neighbours_001A_openfold'\n","\n","# 1. Create Output Directory\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","# Check if file exists\n","if os.path.exists(input_file):\n","    print(\"Loading data for plotting...\")\n","    df = pd.read_csv(input_file)\n","\n","    # Filter data\n","    diff_seq_data = df[df['sequences_identical'] == 0]\n","    same_seq_data = df[df['sequences_identical'] == 1]\n","\n","    # Common Plot Settings\n","    x_label = r'$L_{\\infty}$ distance on pairs of BRI, Angstroms'\n","    y_label = 'Pairs of close chains'\n","    bins_range = (0, 0.01)\n","    bin_width = 0.001\n","\n","    # Helper function to generate plots efficiently\n","    def generate_histogram(data, color, filename_suffix, log_scale=False):\n","        plt.figure(figsize=(10, 6))\n","        sns.set_style(\"whitegrid\")\n","        sns.set(font_scale=1.2)\n","\n","        # Plot (Note: edgecolor removed to drop black border)\n","        sns.histplot(\n","            data=data,\n","            x='full_chebyshev_dist',\n","            binwidth=bin_width,\n","            binrange=bins_range,\n","            color=color,\n","            element=\"bars\",\n","            linewidth=0  # Explicitly ensure no border\n","        )\n","\n","        if log_scale:\n","            plt.yscale('log')\n","            filename_suffix += \"_log\"\n","\n","        plt.xlabel(x_label)\n","        plt.ylabel(y_label)\n","        # No Title\n","\n","        plt.tight_layout()\n","\n","        # Construct filename\n","        filename = f'PDB727K_pairwise_BRI_comparisons_{filename_suffix}.png'\n","        save_path = os.path.join(output_dir, filename)\n","\n","        plt.savefig(save_path)\n","        plt.close()\n","\n","        print(f\"Saved: {save_path}\")\n","\n","    # --- Generate the 4 Plots ---\n","\n","    # 1. Linear Scale\n","    generate_histogram(diff_seq_data, 'orange', 'different_seq', log_scale=False)\n","    generate_histogram(same_seq_data, 'cornflowerblue', 'identical_seq', log_scale=False)\n","\n","    # 2. Log Scale\n","    generate_histogram(diff_seq_data, 'orange', 'different_seq', log_scale=True)\n","    generate_histogram(same_seq_data, 'cornflowerblue', 'identical_seq', log_scale=True)\n","\n","else:\n","    print(f\"Input file not found: {input_file}\")\n","    print(\"Please ensure you have run the 'Full Comparison' step to generate the results CSV.\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":0}