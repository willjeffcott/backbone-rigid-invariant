{"cells":[{"cell_type":"markdown","metadata":{"id":"RYVvHHy6WGo5"},"source":["# 08 OpenFold Geometric Nearest Neighbours\n","# This notebook identifies overlapping chains between the User dataset and OpenFold,\n","# and performs a hierarchical geometric nearest neighbour search (Mean -> Full).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLXwqXjUWGo7","executionInfo":{"status":"ok","timestamp":1770370707719,"user_tz":0,"elapsed":15868,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"9d724bec-2de9-4535-fcb7-321e09167ac9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Changed directory to /content/drive/MyDrive/BRI Analysis\n"]}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","# Change directory to the working folder if necessary\n","try:\n","    os.chdir('/content/drive/MyDrive/BRI Analysis')\n","    print(\"Changed directory to /content/drive/MyDrive/BRI Analysis\")\n","except:\n","    print(\"Could not change directory. Please check the path.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhFHuBdnWGo8","executionInfo":{"status":"ok","timestamp":1770370712237,"user_tz":0,"elapsed":1684,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"4484b116-1922-4cbe-dff1-c37eddff05d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Environment Setup Complete.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import json\n","from scipy.spatial import cKDTree\n","import glob\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm.notebook import tqdm\n","import gc\n","\n","# Paths\n","DATA_DIR = './data'\n","PLOTS_DIR = './plotting/nearest_neighbours_08'\n","BRI_DATA_DIR = './data/bri_computations' # Adjust if necessary\n","\n","os.makedirs(PLOTS_DIR, exist_ok=True)\n","os.makedirs(DATA_DIR, exist_ok=True)\n","print(\"Environment Setup Complete.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uEHEefWNWGo9","executionInfo":{"status":"ok","timestamp":1770370715554,"user_tz":0,"elapsed":2718,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"e60ab826-e477-49ba-eff6-cb3d93c2b272"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading User Data Mapping from ./data/cleaned_connective_chains_auth_chain_id.csv...\n","Loaded 478074 user chains.\n"]}],"source":["# @title 1. Load Data Mapping\n","# Load User Data Mapping (Label -> Author Chain ID) to bridge datasets.\n","\n","user_chain_map_path = os.path.join(DATA_DIR, 'cleaned_connective_chains_auth_chain_id.csv')\n","print(f\"Loading User Data Mapping from {user_chain_map_path}...\")\n","\n","if os.path.exists(user_chain_map_path):\n","    df_user = pd.read_csv(user_chain_map_path)\n","    # Ensure columns are strings\n","    df_user['pdb_id'] = df_user['pdb_id'].astype(str).str.upper()\n","    df_user['author_chain_id'] = df_user['author_chain_id'].astype(str)\n","    df_user['author_chain_id'] = df_user['author_chain_id'].fillna('NA')\n","    print(f\"Loaded {len(df_user)} user chains.\")\n","else:\n","    raise FileNotFoundError(f\"Mapping file not found: {user_chain_map_path}\")\n"]},{"cell_type":"code","source":["# @title 2. Generate mean invariants with corresponding batch number\n","\n","import os\n","import pandas as pd\n","import tqdm\n","import gc\n","\n","# @title 1. Generate Mean Invariants with Batch Numbers\n","inv_dir = \"./data/bri_computations\"\n","output_file = \"./data/PDB727K_mean_invariants_with_batch.csv\"\n","\n","if os.path.exists(output_file):\n","    os.remove(output_file)\n","\n","# Get files and sort them to ensure deterministic order (optional but good practice)\n","files = sorted([f for f in os.listdir(inv_dir) if f.endswith('.parquet')])\n","\n","def calculate_means(df):\n","    # Calculate means for unique group in 'pdb_id', 'model_id', 'chain_id'\n","    bri_cols = ['x(N)', 'y(N)', 'z(N)', 'x(A)', 'y(A)', 'z(A)', 'x(C)', 'y(C)',\n","       'z(C)']\n","\n","    means = df.groupby(['pdb_id', 'model_id', 'chain_id', 'start_residue', 'chain_length'])[bri_cols].mean().reset_index()\n","    return means\n","\n","\n","for i, filename in enumerate(tqdm.tqdm(files, desc=\"Processing Batches\")):\n","    try:\n","        # Extract batch number from filename \"batch_123.parquet\"\n","        # Adjust split logic if your naming convention differs\n","        try:\n","            batch_num = int(filename.split('_')[1].split('.')[0])\n","        except (IndexError, ValueError):\n","            # Fallback if filename is weird, though user stated \"batch_i.parquet\"\n","            print(f\"Warning: Could not parse batch number from {filename}. assigning {i}.\")\n","            batch_num = i\n","\n","        inv_data = pd.read_parquet(os.path.join(inv_dir, filename))\n","\n","        inv_data['chain_id'] = inv_data['chain_id'].astype(str)\n","        inv_data['chain_id'] = inv_data['chain_id'].fillna('NA')\n","\n","        # Calculate means\n","        mean_data = calculate_means(inv_data)\n","\n","        # --- ADD BATCH NUMBER ---\n","        mean_data['batch_number'] = batch_num\n","\n","        # Write incrementally\n","        mode = 'w' if i == 0 else 'a'\n","        header = (i == 0)\n","        mean_data.to_csv(output_file, index=False, mode=mode, header=header)\n","\n","        del inv_data, mean_data\n","        if i % 10 == 0: gc.collect()\n","\n","    except Exception as e:\n","        print(f\"Skipping {filename} due to error: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jtZ379Vb8Zk","executionInfo":{"status":"ok","timestamp":1770371068962,"user_tz":0,"elapsed":347077,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"0ff595d6-c9d4-456a-cbf2-905182c4d242"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Batches: 100%|██████████| 146/146 [05:48<00:00,  2.39s/it]\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RVU3mfwPWGo-","executionInfo":{"status":"ok","timestamp":1770374035701,"user_tz":0,"elapsed":7073,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"e00bc340-08bd-40e9-a733-ab881be2c6e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading OpenFold duplicate chains...\n","Found 472464 OpenFold duplicate chains.\n","Loading OpenFold Chain Cache...\n","Loaded 128793 unique OpenFold chains.\n"]}],"source":["# @title 3. Load OpenFold Data\n","# Load Duplicate list and Chain Cache to identify valid OpenFold chains.\n","\n","of_cache_path = os.path.join(DATA_DIR, 'openfold_chain_data_cache.json')\n","of_duplicates_path = os.path.join(DATA_DIR, 'openfold_duplicate_chains.txt')\n","\n","of_duplicates = set()\n","if os.path.exists(of_duplicates_path):\n","    print(\"Loading OpenFold duplicate chains...\")\n","    with open(of_duplicates_path, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            if len(parts) > 1:\n","                # Exclude representative (first item) and keep duplicates\n","                for dup in parts[1:]:\n","                    of_duplicates.add(dup.upper())\n","    print(f\"Found {len(of_duplicates)} OpenFold duplicate chains.\")\n","else:\n","    print(\"Warning: OpenFold duplicate chains file not found. Skipping duplicate filter.\")\n","\n","print(\"Loading OpenFold Chain Cache...\")\n","if os.path.exists(of_cache_path):\n","    with open(of_cache_path, 'r') as f:\n","        of_data = json.load(f)\n","\n","    of_chains = set()\n","    for key in of_data:\n","        if key.upper() not in of_duplicates:\n","            # key format is '1ABC_A'\n","            parts = key.split('_')\n","            if len(parts) >= 2:\n","                pdb_id = parts[0].upper()\n","                chain_id = parts[1]\n","                # if chain_id is np.nan then convert to 'NA'\n","                if pd.isna(chain_id):\n","                    chain_id = 'NA'\n","\n","                of_chains.add((pdb_id, chain_id))\n","    print(f\"Loaded {len(of_chains)} unique OpenFold chains.\")\n","else:\n","    raise FileNotFoundError(f\"OpenFold cache not found: {of_cache_path}\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0lGH-PyWGo-","executionInfo":{"status":"ok","timestamp":1770374038606,"user_tz":0,"elapsed":6,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"cdeefaf2-833d-4d25-f5f3-e3bfba9dbf96"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 58971 overlapping chains.\n"]}],"source":["# @title 3. Identify Overlap\n","# Find intersection: User (Author Chain ID) ∩ OpenFold (Chain ID)\n","\n","user_keys = set(zip(df_user['pdb_id'], df_user['author_chain_id']))\n","overlap_keys = user_keys.intersection(of_chains)\n","target_chains_set = set(overlap_keys)\n","\n","print(f\"Found {len(overlap_keys)} overlapping chains.\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jq2I3CWYWGo_","executionInfo":{"status":"ok","timestamp":1770374050474,"user_tz":0,"elapsed":5732,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"18be6f30-05f6-4668-a455-e6735a182c88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Mean Invariants from ./data/PDB727K_mean_invariants_with_batch.csv...\n","Merging with Author Chain IDs...\n","Loading Metadata from ./data/PDB727K_webscrape_meta_data.csv...\n","Pre-filter count: 58929\n","Post-filter count: 44405\n","Original Mean Invariants: 477859\n","Filtered Target Mean Invariants: 44405\n"]}],"source":["# @title 4. Filter Mean Invariants\n","# Filter the user's mean invariants file to only include the overlapping chains.\n","\n","mean_invariants_path = os.path.join(DATA_DIR, 'PDB727K_mean_invariants_with_batch.csv')\n","print(f\"Loading Mean Invariants from {mean_invariants_path}...\")\n","\n","if os.path.exists(mean_invariants_path):\n","    df_mean = pd.read_csv(mean_invariants_path)\n","    # Check column names for PDB/Chain\n","    # Assuming 'pdb_id' and 'chain_id' (Label) are present\n","    df_mean['pdb_id'] = df_mean['pdb_id'].astype(str).str.upper()\n","    df_mean['chain_id'] = df_mean['chain_id'].astype(str)\n","    df_mean['chain_id'] = df_mean['chain_id'].fillna('NA')\n","\n","    df_mean = df_mean[df_mean['model_id']==1].copy()\n","\n","    # Map to Author ID using user_map\n","    df_user_map = df_user[['pdb_id', 'chain_id', 'author_chain_id']].drop_duplicates()\n","\n","    print(\"Merging with Author Chain IDs...\")\n","    df_mean_mapped = df_mean.merge(df_user_map, on=['pdb_id', 'chain_id'], how='inner')\n","\n","    # Filter by target_chains_set (pdb_id, author_chain_id)\n","    df_mean_mapped['match_key'] = list(zip(df_mean_mapped['pdb_id'], df_mean_mapped['author_chain_id']))\n","    df_target = df_mean_mapped[df_mean_mapped['match_key'].isin(target_chains_set)].copy()\n","\n","# --- NEW: Load Metadata and Filter ---\n","# Added by automated script to match 07_finding_differences logic\n","meta_data_path = os.path.join(DATA_DIR, 'PDB727K_webscrape_meta_data.csv')\n","if os.path.exists(meta_data_path):\n","    print(f\"Loading Metadata from {meta_data_path}...\")\n","    meta_data = pd.read_csv(meta_data_path)\n","\n","    # Clean Resolution\n","    # '[2.55]' -> '2.55'\n","    clean_step_1 = meta_data['Resolution'].astype(str).str.strip('[]')\n","    clean_step_2 = clean_step_1.str.split(',').str[0]\n","    meta_data['resolution'] = pd.to_numeric(clean_step_2, errors='coerce')\n","\n","    # Clean Release Date\n","    meta_data['release_date'] = pd.to_datetime(meta_data['release_date'])\n","    meta_data['release_date'] = meta_data['release_date'].dt.tz_localize(None).dt.normalize()\n","\n","    # Merge metadata into df_target\n","    # Note: df_target is created from df_mean_mapped further down in the original cell.\n","    # We should inject this Logic AFTER df_target is created.\n","\n","    # Join metadata\n","    # We left join on pdb_id\n","    df_target = df_target.merge(meta_data[['pdb_id', 'resolution', 'release_date']], on='pdb_id', how='left')\n","\n","    print(f\"Pre-filter count: {len(df_target)}\")\n","    # Apply Filters: Chain Length >= 16, Resolution <= 9, Release Date <= 2021-10-10\n","    df_target = df_target[\n","        (df_target['chain_length'] >= 16) &\n","        (df_target['resolution'] <= 9) &\n","        (df_target['release_date'] <= '2021-10-10')\n","    ]\n","    print(f\"Post-filter count: {len(df_target)}\")\n","\n","    print(f\"Original Mean Invariants: {len(df_mean)}\")\n","    print(f\"Filtered Target Mean Invariants: {len(df_target)}\")\n","\n","    # Clean up to save memory\n","    #del df_mean, df_mean_mapped\n","    #gc.collect()\n","else:\n","    raise FileNotFoundError(f\"Mean Invariants file not found: {mean_invariants_path}\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYMAxfHiWGpA","executionInfo":{"status":"ok","timestamp":1770374079852,"user_tz":0,"elapsed":1450,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"e7a42fe3-d7f1-42a3-b3c8-f3c53e708521"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using 10 features for comparison.\n","Writing pairs to ./data/PDB727K_openfold_mean_pairs.csv...\n"]},{"output_type":"stream","name":"stderr","text":["Processing Lengths: 100%|██████████| 958/958 [00:01<00:00, 850.57it/s] "]},{"output_type":"stream","name":"stdout","text":["Phase 1 Complete. Found 5062 pairs.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# @title 5. Phase 1: Mean Invariant Comparison\n","# Perform coarse nearest neighbour search using Mean Invariants with Chebyshev distance.\n","\n","mean_pairs_output = os.path.join(DATA_DIR, 'PDB727K_openfold_mean_pairs.csv')\n","RADIUS = 0.01\n","\n","# Identify Feature Columns (assuming numeric columns excluding metadata)\n","meta_cols = {'pdb_id', 'chain_id', 'author_chain_id', 'model_id', 'start_residue', 'chain_length', 'batch_number', 'match_key'}\n","feature_cols = [c for c in df_target.columns if c not in meta_cols and np.issubdtype(df_target[c].dtype, np.number)]\n","\n","# Sanity check for feature columns\n","if len(feature_cols) < 5:\n","    print(f\"Warning: Only found {len(feature_cols)} features. Checking for 'inv_' prefix.\")\n","    feature_cols = [c for c in df_target.columns if c.startswith('inv_')]\n","\n","print(f\"Using {len(feature_cols)} features for comparison.\")\n","\n","# Prepare Output\n","id_cols = ['pdb_id', 'chain_id', 'author_chain_id', 'chain_length', 'batch_number']\n","header = [f\"{c}_1\" for c in id_cols] + [f\"{c}_2\" for c in id_cols] + ['chebyshev_dist']\n","\n","# Group by Chain Length\n","grouped = df_target.groupby('chain_length')\n","total_pairs = 0\n","\n","print(f\"Writing pairs to {mean_pairs_output}...\")\n","with open(mean_pairs_output, 'w') as f_out:\n","    f_out.write(','.join(header) + '\\n')\n","\n","    for length, group in tqdm.tqdm(grouped, desc=\"Processing Lengths\"):\n","        if len(group) < 2: continue\n","\n","        points = group[feature_cols].values\n","\n","        # Build cKDTree\n","        try:\n","            tree = cKDTree(points)\n","            # Query pairs within Radius (p=np.inf for Chebyshev)\n","            pairs = tree.query_pairs(r=RADIUS, p=np.inf)\n","        except Exception as e:\n","            print(f\"Error processing length {length}: {e}\")\n","            continue\n","\n","        if not pairs: continue\n","\n","        pairs_arr = np.array(list(pairs))\n","\n","        # Calculate precise distances for retrieved pairs\n","        p1 = points[pairs_arr[:, 0]]\n","        p2 = points[pairs_arr[:, 1]]\n","        dists = np.max(np.abs(p1 - p2), axis=1)\n","\n","        # Retrieve IDs\n","        res1 = group.iloc[pairs_arr[:, 0]][id_cols].reset_index(drop=True)\n","        res2 = group.iloc[pairs_arr[:, 1]][id_cols].reset_index(drop=True)\n","\n","        res1.columns = [f\"{c}_1\" for c in id_cols]\n","        res2.columns = [f\"{c}_2\" for c in id_cols]\n","\n","        res_df = pd.concat([res1, res2], axis=1)\n","        res_df['chebyshev_dist'] = dists\n","\n","        # Append to CSV\n","        res_df.to_csv(f_out, header=False, index=False)\n","        total_pairs += len(res_df)\n","\n","print(f\"Phase 1 Complete. Found {total_pairs} pairs.\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUG8XMFgWGpB","executionInfo":{"status":"ok","timestamp":1770374156632,"user_tz":0,"elapsed":69774,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"2fd6daa2-6af0-4f1b-9f5e-291ae5f8fb71"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading pairs to identify relevant chains...\n","Building set of required chains (Assuming Model ID = 1)...\n","Total unique chains to load: 1165\n","Scanning 146 batch files...\n"]},{"output_type":"stream","name":"stderr","text":["Loading Data: 100%|██████████| 146/146 [01:09<00:00,  2.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Successfully loaded 1165 chains into memory.\n","Computing pairwise comparisons...\n"]},{"output_type":"stream","name":"stderr","text":["Comparing: 100%|██████████| 5062/5062 [00:00<00:00, 10985.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved 7 passing pairs to ./data/PDB727K_full_comparison_results_001_seq_openfold.csv\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import tqdm\n","import gc\n","\n","# @title 6. Full Comparison (Memory Optimized: Filter-on-Load)\n","# ==============================================================================\n","# Configuration\n","# ==============================================================================\n","pairs_file = f\"./data/PDB727K_openfold_mean_pairs.csv\"\n","parquet_dir = \"./data/bri_computations\"\n","output_full_diff_file = f\"./data/PDB727K_full_comparison_results_001_seq_openfold.csv\"\n","\n","full_dist_threshold = 0.01\n","\n","# Columns to load from Parquet\n","# We still load 'model_id' to filter by it, even if we assume it is 1\n","id_cols = ['pdb_id', 'model_id', 'chain_id']\n","bri_cols = ['x(N)', 'y(N)', 'z(N)', 'x(A)', 'y(A)', 'z(A)', 'x(C)', 'y(C)', 'z(C)']\n","seq_col = 'residue_label'\n","\n","load_columns = list(set(id_cols + bri_cols + [seq_col]))\n","\n","# ==============================================================================\n","# 1. Identify \"Relevant Chains\"\n","# ==============================================================================\n","if not os.path.exists(pairs_file):\n","    raise FileNotFoundError(\"Run Step 2 first.\")\n","\n","print(\"Loading pairs to identify relevant chains...\")\n","pairs_df = pd.read_csv(pairs_file)\n","\n","if len(pairs_df) == 0:\n","    print(\"No pairs found.\")\n","    exit()\n","\n","# Extract unique keys (Chain 1 and Chain 2) needed for analysis\n","# We use a set of tuples for O(1) lookup: (pdb_id, model_id, chain_id, start_residue, chain_length)\n","# CHANGE: We assume model_id is always 1, so we inject '1' into the key tuples manually.\n","\n","print(\"Building set of required chains (Assuming Model ID = 1)...\")\n","\n","# Create vectors of 1s for the zip operation\n","ones_vector = [1] * len(pairs_df)\n","\n","keys_1 = list(zip(\n","    pairs_df['pdb_id_1'],\n","    ones_vector,          # Hardcoded Model ID 1\n","    pairs_df['chain_id_1']\n","))\n","\n","keys_2 = list(zip(\n","    pairs_df['pdb_id_2'],\n","    ones_vector,          # Hardcoded Model ID 1\n","    pairs_df['chain_id_2']\n","))\n","\n","required_keys = set(keys_1) | set(keys_2)\n","\n","print(f\"Total unique chains to load: {len(required_keys)}\")\n","\n","# ==============================================================================\n","# 2. Load and Filter Data (One Pass over Files)\n","# ==============================================================================\n","# Store data as: chain_data_store[key] = {'mat': np.array, 'seq': str}\n","chain_data_store = {}\n","\n","# Get list of batch files\n","batch_files = sorted([f for f in os.listdir(parquet_dir) if f.endswith('.parquet')])\n","\n","print(f\"Scanning {len(batch_files)} batch files...\")\n","\n","for f in tqdm.tqdm(batch_files, desc=\"Loading Data\"):\n","    try:\n","        path = os.path.join(parquet_dir, f)\n","\n","        # Load batch (only relevant columns)\n","        df = pd.read_parquet(path, columns=load_columns)\n","\n","        # --- NEW FILTERING STEP ---\n","        # Strictly filter for model_id == 1\n","        df = df[df['model_id'] == 1]\n","\n","        if df.empty:\n","            continue\n","\n","        # Create a tuple key column for filtering\n","        # Note: Vectorized zip is faster than apply\n","        current_keys = list(zip(\n","            df['pdb_id'],\n","            df['model_id'],\n","            df['chain_id']\n","        ))\n","\n","        # Filter: keep rows where the key is in our required set\n","        mask = [k in required_keys for k in current_keys]\n","\n","        if not any(mask):\n","            continue # Nothing useful in this batch\n","\n","        filtered_df = df[mask].copy()\n","\n","        # Group by chain to extract Matrix and Sequence\n","        # We groupby the full key\n","        grouped = filtered_df.groupby(id_cols)\n","\n","        for key, group in grouped:\n","            # key is the tuple (pdb, model, chain, start, length)\n","\n","            # Extract Matrix\n","            mat = group[bri_cols].to_numpy()\n","\n","            # Extract Sequence\n","            labels = group[seq_col]\n","            if len(labels) > 0 and isinstance(labels.iloc[0], str):\n","                # Standard case: sequence of characters\n","                seq = \"\".join(labels)\n","            else:\n","                seq = \"\"\n","\n","            chain_data_store[key] = {'mat': mat, 'seq': seq}\n","\n","        del df, filtered_df, mask, current_keys\n","        # gc.collect()\n","\n","    except Exception as e:\n","        print(f\"Error reading {f}: {e}\")\n","\n","print(f\"Successfully loaded {len(chain_data_store)} chains into memory.\")\n","\n","# ==============================================================================\n","# 3. Compute Distances\n","# ==============================================================================\n","print(\"Computing pairwise comparisons...\")\n","\n","results_list = []\n","\n","# Iterate through pairs and lookup data from memory\n","for idx, row in tqdm.tqdm(pairs_df.iterrows(), total=len(pairs_df), desc=\"Comparing\"):\n","\n","    # CHANGE: Hardcoded '1' for model_id in the lookup key\n","    key1 = (row['pdb_id_1'], 1, row['chain_id_1'])\n","    key2 = (row['pdb_id_2'], 1, row['chain_id_2'])\n","\n","    # Retrieve data\n","    if key1 not in chain_data_store or key2 not in chain_data_store:\n","        # Should not happen if logic is correct, but safe to skip\n","        continue\n","\n","    data1 = chain_data_store[key1]\n","    data2 = chain_data_store[key2]\n","\n","    mat1 = data1['mat']\n","    mat2 = data2['mat']\n","\n","    # Check length compatibility\n","    min_len = min(len(mat1), len(mat2))\n","\n","    # Compute Distance\n","    dist = np.max(np.abs(mat1[:min_len] - mat2[:min_len]))\n","\n","    # Check Threshold\n","    if dist <= full_dist_threshold:\n","        seq1 = data1['seq']\n","        seq2 = data2['seq']\n","\n","        res_row = row.to_dict()\n","        res_row['full_chebyshev_dist'] = dist\n","        res_row['sequence_1'] = seq1\n","        res_row['sequence_2'] = seq2\n","        res_row['sequences_identical'] = 1 if seq1 == seq2 else 0\n","\n","        results_list.append(res_row)\n","\n","# ==============================================================================\n","# 4. Save Results\n","# ==============================================================================\n","if results_list:\n","    final_df = pd.DataFrame(results_list)\n","    final_df.to_csv(output_full_diff_file, index=False)\n","    print(f\"Saved {len(final_df)} passing pairs to {output_full_diff_file}\")\n","else:\n","    print(\"No pairs passed the full distance threshold.\")"]},{"cell_type":"code","source":["final_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"Ox3ceKEOo913","executionInfo":{"status":"ok","timestamp":1770374156684,"user_tz":0,"elapsed":50,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"e974a255-d935-45f9-f1d6-305086157e79"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  pdb_id_1 chain_id_1 author_chain_id_1  chain_length_1  batch_number_1  \\\n","0     3IYL          A                 A              41              57   \n","1     4G6D          A                 A              62              64   \n","2     2BSQ          E                 E              68              23   \n","3     2BSQ          A                 A             143              23   \n","4     1CE7          A                 A             241               2   \n","5     5MXN          B                 A             473              78   \n","6     7ADJ          A                 A             613             105   \n","\n","  pdb_id_2 chain_id_2 author_chain_id_2  chain_length_2  batch_number_2  \\\n","0     5ZVT          K                 A              41              84   \n","1     4G94          A                 A              62              64   \n","2     2H1O          G                 E              68              29   \n","3     2H1O          C                 A             143              29   \n","4     2MLL          A                 A             241              46   \n","5     5OJQ          B                 A             473              79   \n","6     7ADK          A                 A             613             105   \n","\n","   chebyshev_dist  full_chebyshev_dist  \\\n","0        0.000000                0.000   \n","1        0.000000                0.000   \n","2        0.000000                0.000   \n","3        0.000000                0.000   \n","4        0.000000                0.000   \n","5        0.000063                0.003   \n","6        0.000000                0.000   \n","\n","                                          sequence_1  \\\n","0          GNVQTSVNTYNITGDGNSFTPTSDMTSTAAPAIDLKPGVLN   \n","1  MKEQLEDVLDTLTDREENVLRLRFGLDDGRTRTLEEVGKVFGVTRE...   \n","2  ASVVIRNLSEATHNAIKFRARAAGRSTEAEIRLILDNIAKAQQTVR...   \n","3  MILLDTNVISEPLRPQPNERVVAWLDSLILEDVYLSAITVAEMRLG...   \n","4  YERGDLDVTAQTTGAGYFSFITLLRDYVSSGSFSNAIPLLSQSGGG...   \n","5  GSLLDEIMAQTRIAPSEEGYDIAKKGVAAFIENLMGSQHSAEPVNK...   \n","6  RKQTITIAGIEVEAEIEGPPGFVTHQRDKDRKISNPTKPYQNHTVN...   \n","\n","                                          sequence_2  sequences_identical  \n","0          GNVQTSVNTYNITGDGNSFTPTSDMTSTAAPAIDLKPGVLN                    1  \n","1  MKEQLEDVLDTLTDREENVLRLRFGLDDGRTRTLEEVGKVFGVTRE...                    1  \n","2  ASVVIRNLSEATHNAIKFRARAAGRSTEAEIRLILDNIAKAQQTVR...                    1  \n","3  MILLDTNVISEPLRPQPNERVVAWLDSLILEDVYLSAITVAEMRLG...                    1  \n","4  YERGDLDVTAQTTGAGYFSFITLLRDYVSSGSFSNAIPLLSQSGGG...                    0  \n","5  GSLLDEIMAQTRCAPSEEGYDIAKKGVAAFIENLMGSQHSAEPVNK...                    0  \n","6  RKQTITIAGIEVEAEIEGPPGFVTHQRDKDRKISNPTKPYQNHTVN...                    1  "],"text/html":["\n","  <div id=\"df-cd6945c1-3443-4ab0-88b2-9e3e5b2c9019\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pdb_id_1</th>\n","      <th>chain_id_1</th>\n","      <th>author_chain_id_1</th>\n","      <th>chain_length_1</th>\n","      <th>batch_number_1</th>\n","      <th>pdb_id_2</th>\n","      <th>chain_id_2</th>\n","      <th>author_chain_id_2</th>\n","      <th>chain_length_2</th>\n","      <th>batch_number_2</th>\n","      <th>chebyshev_dist</th>\n","      <th>full_chebyshev_dist</th>\n","      <th>sequence_1</th>\n","      <th>sequence_2</th>\n","      <th>sequences_identical</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3IYL</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>41</td>\n","      <td>57</td>\n","      <td>5ZVT</td>\n","      <td>K</td>\n","      <td>A</td>\n","      <td>41</td>\n","      <td>84</td>\n","      <td>0.000000</td>\n","      <td>0.000</td>\n","      <td>GNVQTSVNTYNITGDGNSFTPTSDMTSTAAPAIDLKPGVLN</td>\n","      <td>GNVQTSVNTYNITGDGNSFTPTSDMTSTAAPAIDLKPGVLN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4G6D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>62</td>\n","      <td>64</td>\n","      <td>4G94</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>62</td>\n","      <td>64</td>\n","      <td>0.000000</td>\n","      <td>0.000</td>\n","      <td>MKEQLEDVLDTLTDREENVLRLRFGLDDGRTRTLEEVGKVFGVTRE...</td>\n","      <td>MKEQLEDVLDTLTDREENVLRLRFGLDDGRTRTLEEVGKVFGVTRE...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2BSQ</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>68</td>\n","      <td>23</td>\n","      <td>2H1O</td>\n","      <td>G</td>\n","      <td>E</td>\n","      <td>68</td>\n","      <td>29</td>\n","      <td>0.000000</td>\n","      <td>0.000</td>\n","      <td>ASVVIRNLSEATHNAIKFRARAAGRSTEAEIRLILDNIAKAQQTVR...</td>\n","      <td>ASVVIRNLSEATHNAIKFRARAAGRSTEAEIRLILDNIAKAQQTVR...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2BSQ</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>143</td>\n","      <td>23</td>\n","      <td>2H1O</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>143</td>\n","      <td>29</td>\n","      <td>0.000000</td>\n","      <td>0.000</td>\n","      <td>MILLDTNVISEPLRPQPNERVVAWLDSLILEDVYLSAITVAEMRLG...</td>\n","      <td>MILLDTNVISEPLRPQPNERVVAWLDSLILEDVYLSAITVAEMRLG...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1CE7</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>241</td>\n","      <td>2</td>\n","      <td>2MLL</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>241</td>\n","      <td>46</td>\n","      <td>0.000000</td>\n","      <td>0.000</td>\n","      <td>YERGDLDVTAQTTGAGYFSFITLLRDYVSSGSFSNAIPLLSQSGGG...</td>\n","      <td>YERGDLDVTAQTTGAGYFSFITLLRDYVSSGSFSNAIPLLSQSGGG...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5MXN</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>473</td>\n","      <td>78</td>\n","      <td>5OJQ</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>473</td>\n","      <td>79</td>\n","      <td>0.000063</td>\n","      <td>0.003</td>\n","      <td>GSLLDEIMAQTRIAPSEEGYDIAKKGVAAFIENLMGSQHSAEPVNK...</td>\n","      <td>GSLLDEIMAQTRCAPSEEGYDIAKKGVAAFIENLMGSQHSAEPVNK...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7ADJ</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>613</td>\n","      <td>105</td>\n","      <td>7ADK</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>613</td>\n","      <td>105</td>\n","      <td>0.000000</td>\n","      <td>0.000</td>\n","      <td>RKQTITIAGIEVEAEIEGPPGFVTHQRDKDRKISNPTKPYQNHTVN...</td>\n","      <td>RKQTITIAGIEVEAEIEGPPGFVTHQRDKDRKISNPTKPYQNHTVN...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd6945c1-3443-4ab0-88b2-9e3e5b2c9019')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cd6945c1-3443-4ab0-88b2-9e3e5b2c9019 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cd6945c1-3443-4ab0-88b2-9e3e5b2c9019');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_27340df1-ec10-4bf9-b382-3fc8eed28443\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_27340df1-ec10-4bf9-b382-3fc8eed28443 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('final_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"final_df","summary":"{\n  \"name\": \"final_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"pdb_id_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"3IYL\",\n          \"4G6D\",\n          \"7ADJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_id_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"A\",\n          \"E\",\n          \"B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_chain_id_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"E\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_length_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 224,\n        \"min\": 41,\n        \"max\": 613,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          41,\n          62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_number_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 2,\n        \"max\": 105,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          57,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdb_id_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"5ZVT\",\n          \"4G94\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_id_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A\",\n          \"B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_chain_id_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"E\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_length_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 224,\n        \"min\": 41,\n        \"max\": 613,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          41,\n          62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_number_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 29,\n        \"max\": 105,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          84,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chebyshev_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.397237672363662e-05,\n        \"min\": 0.0,\n        \"max\": 6.342494714589586e-05,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6.342494714589586e-05,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_chebyshev_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0011338934190276827,\n        \"min\": 0.0,\n        \"max\": 0.0030000000000000027,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0030000000000000027,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"GNVQTSVNTYNITGDGNSFTPTSDMTSTAAPAIDLKPGVLN\",\n          \"MKEQLEDVLDTLTDREENVLRLRFGLDDGRTRTLEEVGKVFGVTRERIRQIEAKALRKLRHP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"GNVQTSVNTYNITGDGNSFTPTSDMTSTAAPAIDLKPGVLN\",\n          \"MKEQLEDVLDTLTDREENVLRLRFGLDDGRTRTLEEVGKVFGVTRERIRQIEAKALRKLRHP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequences_identical\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S38rIMFoWGpC","executionInfo":{"status":"ok","timestamp":1770374164225,"user_tz":0,"elapsed":2458,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"}},"outputId":"dc5a3d42-424e-4662-d3fa-5047b5cc6e0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data for plotting...\n","Saved: ./plotting/nearest_neighbours_001A_openfold/PDB727K_pairwise_BRI_comparisons_different_seq.png\n","Saved: ./plotting/nearest_neighbours_001A_openfold/PDB727K_pairwise_BRI_comparisons_identical_seq.png\n","Saved: ./plotting/nearest_neighbours_001A_openfold/PDB727K_pairwise_BRI_comparisons_different_seq_log.png\n","Saved: ./plotting/nearest_neighbours_001A_openfold/PDB727K_pairwise_BRI_comparisons_identical_seq_log.png\n"]}],"source":["# @title 7. Visualization\n","# Generate histogram of pairwise L-inf distances.\n","\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Configuration\n","restrict_suffix = \"\"\n","input_file = f\"./data/PDB727K_full_comparison_results_001_seq_openfold.csv\"\n","output_dir = './plotting/nearest_neighbours_001A_openfold'\n","\n","# 1. Create Output Directory\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","# Check if file exists\n","if os.path.exists(input_file):\n","    print(\"Loading data for plotting...\")\n","    df = pd.read_csv(input_file)\n","\n","    # Filter data\n","    diff_seq_data = df[df['sequences_identical'] == 0]\n","    same_seq_data = df[df['sequences_identical'] == 1]\n","\n","    # Common Plot Settings\n","    x_label = r'$L_{\\infty}$ distance on pairs of BRI, Angstroms'\n","    y_label = 'Pairs of close chains'\n","    bins_range = (0, 0.01)\n","    bin_width = 0.001\n","\n","    # Helper function to generate plots efficiently\n","    def generate_histogram(data, color, filename_suffix, log_scale=False):\n","        plt.figure(figsize=(10, 6))\n","        sns.set_style(\"whitegrid\")\n","        sns.set(font_scale=1.2)\n","\n","        # Plot (Note: edgecolor removed to drop black border)\n","        sns.histplot(\n","            data=data,\n","            x='full_chebyshev_dist',\n","            binwidth=bin_width,\n","            binrange=bins_range,\n","            color=color,\n","            element=\"bars\",\n","            linewidth=0  # Explicitly ensure no border\n","        )\n","\n","        if log_scale:\n","            plt.yscale('log')\n","            filename_suffix += \"_log\"\n","\n","        plt.xlabel(x_label)\n","        plt.ylabel(y_label)\n","        # No Title\n","\n","        plt.tight_layout()\n","\n","        # Construct filename\n","        filename = f'PDB727K_pairwise_BRI_comparisons_{filename_suffix}.png'\n","        save_path = os.path.join(output_dir, filename)\n","\n","        plt.savefig(save_path)\n","        plt.close()\n","\n","        print(f\"Saved: {save_path}\")\n","\n","    # --- Generate the 4 Plots ---\n","\n","    # 1. Linear Scale\n","    generate_histogram(diff_seq_data, 'orange', 'different_seq', log_scale=False)\n","    generate_histogram(same_seq_data, 'cornflowerblue', 'identical_seq', log_scale=False)\n","\n","    # 2. Log Scale\n","    generate_histogram(diff_seq_data, 'orange', 'different_seq', log_scale=True)\n","    generate_histogram(same_seq_data, 'cornflowerblue', 'identical_seq', log_scale=True)\n","\n","else:\n","    print(f\"Input file not found: {input_file}\")\n","    print(\"Please ensure you have run the 'Full Comparison' step to generate the results CSV.\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":0}