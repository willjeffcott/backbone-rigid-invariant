{"cells":[{"cell_type":"code","execution_count":1,"id":"NvVbEJanrotf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19724,"status":"ok","timestamp":1768647850148,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"},"user_tz":0},"id":"NvVbEJanrotf","outputId":"251bda46-954e-4713-da48-552c6755b8ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"id":"2f75d542","metadata":{"executionInfo":{"elapsed":1899,"status":"ok","timestamp":1768647852051,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"},"user_tz":0},"id":"2f75d542"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tqdm\n","from scipy.spatial import KDTree\n","import ast\n","import seaborn as sns\n","import time\n","import os\n","from multiprocessing import Pool\n","import requests\n","import ast\n","from matplotlib.colors import LogNorm\n","import pickle\n","import scipy.sparse as sp\n","from scipy.signal import convolve2d"]},{"cell_type":"code","execution_count":3,"id":"z8QKEwUWr5yq","metadata":{"executionInfo":{"elapsed":598,"status":"ok","timestamp":1768647852674,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"},"user_tz":0},"id":"z8QKEwUWr5yq"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/BRI Analysis')"]},{"cell_type":"code","execution_count":4,"id":"vgBF38XSfobz","metadata":{"executionInfo":{"elapsed":2564,"status":"ok","timestamp":1768647855241,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"},"user_tz":0},"id":"vgBF38XSfobz"},"outputs":[],"source":["%run hist_functions.py"]},{"cell_type":"markdown","id":"2e651035","metadata":{"id":"2e651035"},"source":["### Set up the plotting parameters"]},{"cell_type":"code","execution_count":5,"id":"2d6066f7","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1768647855266,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"},"user_tz":0},"id":"2d6066f7"},"outputs":[],"source":["bri_names_1d = ['x(N)', 'y(N)', 'z(N)', 'x(A)', 'y(A)', 'z(A)', 'x(C)', 'y(C)', 'z(C)']\n","bri_names_1d_latex = ['$x_{BRI}(C_{i-1}N_{i})$','$y_{BRI}(C_{i-1}N_{i})$', '$z_{BRI}(C_{i-1}N_{i})$',\n","                '$x_{BRI}(N_{i}A_{i})$', '$y_{BRI}(N_{i}A_{i})$','$z_{BRI}(N_{i}A_{i})$',\n","                '$x_{BRI}(A_{i}C_{i})$', '$y_{BRI}(A_{i}C_{i})$', '$z_{BRI}(A_{i}C_{i})$']\n","\n","bri_input_parameters_1d = [(0.01,-2.0,2.0),(0.01,-2.0,2.0),(0.01,-2.0,2.0),\n","                           (0.01,-2.0,2.0),(0.01,-2.0,2.0),(0.01,-2.0,2.0),\n","                           (0.01,-2.0,2.0),(0.01,-2.0,2.0),(0.01,-2.0,2.0)]\n","\n","bri_names_2d = []\n","bri_names_2d_latex = []\n","bri_input_parameters_2d = []\n","for i in [(0,1),(0,2),(1,2),(3,4),(3,5),(4,5),(6,7),(6,8),(7,8)]:\n","    bri_names_2d.append((bri_names_1d[i[0]],bri_names_1d[i[1]]))\n","    bri_names_2d_latex.append((bri_names_1d_latex[i[0]],bri_names_1d_latex[i[1]]))\n","    bri_input_parameters_2d.append((0.01,0.01,-2.0,2.0,-2.0,2.0))\n","\n","\n","trin_names_1d = ['x(AN)', 'x(AC)', 'y(AC)']\n","trin_names_1d_latex = ['$x_{TRIN}(A_{i}N_{i})$', '$x_{TRIN}(A_{i}C_{i})$', '$y_{TRIN}(A_{i}C_{i})$']\n","\n","trin_input_parameters_1d = [(0.01,-3.0,3.0),(0.01,-3.0,3.0),(0.01,-3.0,3.0)]\n","\n","trin_names_2d = []\n","trin_names_2d_latex = []\n","trin_input_parameters_2d = []\n","for i in [(0,1),(0,2),(1,2)]:\n","    trin_names_2d.append((trin_names_1d[i[0]],trin_names_1d[i[1]]))\n","    trin_names_2d_latex.append((trin_names_1d_latex[i[0]],trin_names_1d_latex[i[1]]))\n","    trin_input_parameters_2d.append((0.01,0.01,-3.0,3.0,-3.0,3.0))\n","\n","al_names_1d = ['length(N)', 'length(A)', 'length(C)', 'angle(N)', 'angle(A)', 'angle(C)', 'tau(NA)', 'tau(AC)', 'tau(CN)']\n","\n","al_names_1d_latex = ['$len(C_{i-1}N_{i})$', '$len(N_{i}A_{i})$', '$len(A_{i}C_{i})$',\n","                     '$angle(C_{i-1}N_{i}A_{i})$', '$angle(N_{i}A_{i}C_{i})$','$angle(A_{i}C_{i}N_{i+1})$',\n","                     '$tau(C_{i-1}N_{i}A_{i},N_{i}A_{i}C_{i})$', '$tau(N_{i}A_{i}C_{i},A_{i}C_{i}N_{i+1})$','$tau(A_{i-1}C_{i-1}N_{i},C_{i-1}N_{i}A_{i})$']\n","\n","al_input_parameters_1d = [(0.01,0.0,3.0),(0.01,0.0,3.0),(0.01,0.0,3.0),\n"," (0.1,0.0,180.0),(0.1,0.0,180.0),(0.1,0.0,180.0),\n","  (0.1,-180.0,180.0),(0.1,-180.0,180.0),(0.1,-180.0,180.0)]\n","\n","al_names_2d = []\n","al_names_2d_latex = []\n","al_input_parameters_2d = []\n","for i in [(0,1),(0,2),(1,2),\n","          (3,4),(3,5),(4,5),\n","          (6,7),(6,8),(7,8)]:\n","\n","    al_names_2d.append((al_names_1d[i[0]],al_names_1d[i[1]]))\n","    al_names_2d_latex.append((al_names_1d_latex[i[0]],al_names_1d_latex[i[1]]))\n","    if i in [(0,1),(0,2),(1,2)]:\n","        al_input_parameters_2d.append((0.01,0.01,0.0,3.0,0.0,3.0))\n","    elif i in [(3,4),(3,5),(4,5)]:\n","        al_input_parameters_2d.append((0.1,0.1,0.0,180.0,0.0,180.0))\n","    elif i in [(6,7),(6,8),(7,8)]:\n","        al_input_parameters_2d.append((0.1,0.1,-180.0,180.0,-180.0,180.0))\n","    else:\n","        al_input_parameters_2d.append((0.01,0.01,-1.0,1.0,-1.0,1.0))\n"]},{"cell_type":"code","execution_count":6,"id":"82c8f94a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1423,"status":"ok","timestamp":1768647859061,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"},"user_tz":0},"id":"82c8f94a","outputId":"b49ddce4-325b-45b1-972a-34bd7015be48"},"outputs":[{"name":"stdout","output_type":"stream","text":["['batch_0.parquet', 'batch_1.parquet', 'batch_2.parquet', 'batch_3.parquet', 'batch_4.parquet', 'batch_5.parquet', 'batch_6.parquet', 'batch_7.parquet', 'batch_8.parquet', 'batch_9.parquet', 'batch_10.parquet', 'batch_11.parquet', 'batch_12.parquet', 'batch_13.parquet', 'batch_14.parquet', 'batch_15.parquet', 'batch_16.parquet', 'batch_17.parquet', 'batch_18.parquet', 'batch_19.parquet', 'batch_20.parquet', 'batch_21.parquet', 'batch_22.parquet', 'batch_23.parquet', 'batch_24.parquet', 'batch_25.parquet', 'batch_26.parquet', 'batch_27.parquet', 'batch_28.parquet', 'batch_29.parquet', 'batch_30.parquet', 'batch_31.parquet', 'batch_32.parquet', 'batch_33.parquet', 'batch_34.parquet', 'batch_35.parquet', 'batch_36.parquet', 'batch_37.parquet', 'batch_38.parquet', 'batch_39.parquet', 'batch_40.parquet', 'batch_41.parquet', 'batch_42.parquet', 'batch_43.parquet', 'batch_44.parquet', 'batch_45.parquet', 'batch_46.parquet', 'batch_47.parquet', 'batch_48.parquet', 'batch_49.parquet', 'batch_50.parquet', 'batch_51.parquet', 'batch_52.parquet', 'batch_53.parquet', 'batch_54.parquet', 'batch_55.parquet', 'batch_56.parquet', 'batch_57.parquet', 'batch_58.parquet', 'batch_59.parquet', 'batch_60.parquet', 'batch_61.parquet', 'batch_62.parquet', 'batch_63.parquet', 'batch_64.parquet', 'batch_65.parquet', 'batch_66.parquet', 'batch_67.parquet', 'batch_68.parquet', 'batch_69.parquet', 'batch_70.parquet', 'batch_71.parquet', 'batch_72.parquet', 'batch_73.parquet', 'batch_74.parquet', 'batch_75.parquet', 'batch_76.parquet', 'batch_77.parquet', 'batch_78.parquet', 'batch_79.parquet', 'batch_80.parquet', 'batch_81.parquet', 'batch_82.parquet', 'batch_83.parquet', 'batch_84.parquet', 'batch_85.parquet', 'batch_86.parquet', 'batch_87.parquet', 'batch_88.parquet', 'batch_89.parquet', 'batch_90.parquet', 'batch_91.parquet', 'batch_92.parquet', 'batch_93.parquet', 'batch_94.parquet', 'batch_95.parquet', 'batch_96.parquet', 'batch_97.parquet', 'batch_98.parquet', 'batch_99.parquet', 'batch_100.parquet', 'batch_101.parquet', 'batch_102.parquet', 'batch_103.parquet', 'batch_104.parquet', 'batch_105.parquet', 'batch_106.parquet', 'batch_107.parquet', 'batch_108.parquet', 'batch_109.parquet', 'batch_110.parquet', 'batch_111.parquet', 'batch_112.parquet', 'batch_113.parquet', 'batch_114.parquet', 'batch_115.parquet', 'batch_116.parquet', 'batch_117.parquet', 'batch_118.parquet', 'batch_119.parquet', 'batch_120.parquet', 'batch_121.parquet', 'batch_122.parquet', 'batch_123.parquet', 'batch_124.parquet', 'batch_125.parquet', 'batch_126.parquet', 'batch_127.parquet', 'batch_128.parquet', 'batch_129.parquet', 'batch_130.parquet', 'batch_131.parquet', 'batch_132.parquet', 'batch_133.parquet', 'batch_134.parquet', 'batch_135.parquet', 'batch_136.parquet', 'batch_137.parquet', 'batch_138.parquet', 'batch_139.parquet', 'batch_140.parquet', 'batch_141.parquet', 'batch_142.parquet', 'batch_143.parquet', 'batch_144.parquet', 'batch_145.parquet']\n"]}],"source":["inv_dir = './data/bri_computations/'\n","invariants = os.listdir(inv_dir)\n","\n","print(invariants)"]},{"cell_type":"code","execution_count":7,"id":"7ea296e4","metadata":{"executionInfo":{"elapsed":3861,"status":"ok","timestamp":1768647862991,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"},"user_tz":0},"id":"7ea296e4"},"outputs":[],"source":["# @title Get list with all chains\n","\n","clean_output_file = f'./data/cleaned_connective_chains.csv'\n","final_clean_df = pd.read_csv(clean_output_file)\n","\n","#replace nan values of final_clean_df['chain_id'] with string 'NA'\n","final_clean_df['chain_id'] = final_clean_df['chain_id'].fillna('NA')\n","final_clean_df['chain_id'] = final_clean_df['chain_id'].astype(str)\n","\n","pdb_ids = final_clean_df['pdb_id'].unique()"]},{"cell_type":"code","execution_count":8,"id":"5af6bb64","metadata":{"executionInfo":{"elapsed":2292,"status":"ok","timestamp":1768647865805,"user":{"displayName":"Will Jeffcott","userId":"07148715354986978812"},"user_tz":0},"id":"5af6bb64"},"outputs":[],"source":["# @title Get meta data\n","\n","meta_data = pd.read_csv('./data/PDB727K_webscrape_meta_data.csv')\n","\n","#restrict to XRD only and then restrict to resolutions leq 2A\n","meta_data_xrd = meta_data[meta_data['Method']=='X-RAY DIFFRACTION'].copy()\n","\n","# 1. Strip the brackets\n","# '[2.55]'      -\u003e '2.55'\n","clean_step_1 = meta_data_xrd['Resolution'].astype(str).str.strip('[]')\n","\n","# 2. Split by comma and take the first element\n","clean_step_2 = clean_step_1.str.split(',').str[0]\n","\n","# 3. Convert to numeric\n","# This will handle the string '2.0' turning into float 2.0\n","# It also turns empty strings '' into NaN\n","meta_data_xrd['Resolution'] = pd.to_numeric(clean_step_2, errors='coerce')\n","\n","meta_data_xrd_lt_2A = meta_data_xrd[meta_data_xrd['Resolution']\u003c=2].copy()\n","pdb_ids_lt_2A = meta_data_xrd_lt_2A['pdb_id'].unique()"]},{"cell_type":"code","execution_count":null,"id":"Ycf9ikbVJ5wP","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Ycf9ikbVJ5wP"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 146/146 [37:07\u003c00:00, 15.25s/it]\n","100%|██████████| 146/146 [1:02:33\u003c00:00, 25.71s/it]\n"]}],"source":["# @title Generate all of the corresponding histograms\n","\n","for should_restrict in [True, False]:\n","\n","    if should_restrict:\n","        pdb_ids_list = pdb_ids_lt_2A\n","    else:\n","        pdb_ids_list = pdb_ids\n","\n","    for i in tqdm.tqdm(os.listdir(inv_dir)):\n","\n","        try:\n","            bri_al_data = pd.read_parquet(inv_dir + \"/\" + i)\n","            i_name = i.split('.')[0]\n","\n","            bri_al_data = bri_al_data[bri_al_data['pdb_id'].isin(pdb_ids_list)].copy()\n","\n","            # Calculate means\n","            bri_al_data_mean = calculate_means(bri_al_data)\n","\n","            # Hack for 'tau(CN)'\n","            bri_al_data['tau(CN)'] = bri_al_data['tau(CN)'].shift(1)\n","\n","            # Dictionary to store EVERYTHING for this file\n","            file_results = {}\n","\n","            # --- 1. Standard Histograms ---\n","            if len(bri_al_data) \u003e 0:\n","                # Store tuple: (histograms, xedges, yedges)\n","                file_results['al_2d'] = create_histogram2d(bri_al_data, al_names_2d, al_input_parameters_2d)\n","                file_results['bri_2d'] = create_histogram2d(bri_al_data, bri_names_2d, bri_input_parameters_2d)\n","                file_results['trin_2d'] = create_histogram2d(bri_al_data, trin_names_2d, trin_input_parameters_2d)\n","\n","                # Store tuple: (histograms, xedges)\n","                file_results['al_1d'] = create_histogram(bri_al_data, al_names_1d, al_input_parameters_1d)\n","                file_results['bri_1d'] = create_histogram(bri_al_data, bri_names_1d, bri_input_parameters_1d)\n","                file_results['trin_1d'] = create_histogram(bri_al_data, trin_names_1d, trin_input_parameters_1d)\n","\n","            # --- 2. Mean Histograms ---\n","            if len(bri_al_data_mean) \u003e 0:\n","                # We use the suffix \"_mean\" in the key to distinguish\n","                file_results['al_2d_mean'] = create_histogram2d_means(bri_al_data_mean, al_names_2d, al_input_parameters_2d)\n","                file_results['bri_2d_mean'] = create_histogram2d_means(bri_al_data_mean, bri_names_2d, bri_input_parameters_2d)\n","                file_results['trin_2d_mean'] = create_histogram2d_means(bri_al_data_mean, trin_names_2d, trin_input_parameters_2d)\n","\n","                file_results['al_1d_mean'] = create_histogram_means(bri_al_data_mean, al_names_1d, al_input_parameters_1d)\n","                file_results['bri_1d_mean'] = create_histogram_means(bri_al_data_mean, bri_names_1d, bri_input_parameters_1d)\n","                file_results['trin_1d_mean'] = create_histogram_means(bri_al_data_mean, trin_names_1d, trin_input_parameters_1d)\n","\n","            # --- Write ONCE per file ---\n","            if file_results:\n","                # Saves as \"{filename}_data.pkl\" (or _restrict.pkl)\n","                pickler_write(f\"{i_name}_data\", file_results, restrict=should_restrict)\n","\n","        except Exception as e:\n","            print(f\"Skipping {i} due to error: {e}\")\n","            continue"]}],"metadata":{"colab":{"machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}